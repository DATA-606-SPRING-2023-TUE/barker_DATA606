# PHASE I: PROJECT PROPOSAL & PLANNING
### Data 606 Capstone: Tuesday
### By: Barker French

---
<br>

**Topic**
<p>My project will evaluate the effectiveness of two Named Entity Recognition (NER) models in identifying entities of interest in a dataset of movie trivia questions. NER is an important area of study because it helps to bring order to and make use of the large volumes of unstructured data produced daily.  Help is needed in classifying unstructured data because unstructured data represents 80% of the data generated on a daily basis, and humans don't have the capacity to consume and classify all of this data without the help of computers.</p>
<br>

**Motivation/Techiniques**
<p>While many off the shelf NER models exist, these models classify text into general categories that are relevant across many types of data.  For example, spaCy's standard NER model includes the general categories of "person", "organization", "date", etc.  While this text classification capability is powerful, it leaves gaps for important, specific business use cases in areas like law, medicine, customer relations, etc.  These specific business use cases require a more specialized NER tool.  Keeping in mind the need to fulfill specific use case requirements like these, my project will center on building an NER tool capable of classifying movie trivia questions. I will then compare this custom model's performance against spaCy's mainstream NER model that I will train on movie trivia question data.  The custom NER tool I build will be heavily based on a custom NER discussed in Text Analytics with Python by Dipanjan Sarkar.</p>
<br>

**Research Questions/Metrics**
<p>In building and training these models.  The following questions will be answered:

 - At what performance level can a standard NER tool be trained to work on specific data sets?
 - At what performance level can a custom NER tool be trained to work on specific data sets?
 - How does the performance of trained standard NER compare to the performance of the standard version used on standard documents?
 - What kinds of techniques can be used to improve a given model's performance?

Because at its core NER is a classification problem, the answers to the above  performance based questions will be based on several quantitative measures used in classification problems, including Precision, Recall, F-Score, and Accuracy.
</p>
<br>

**Dataset**
<p>The data that will be used to train both the existing and custom NER models comes from MIT's Spoken Language Systems project, a part of MIT's Computer Science and Artificial Intelligence Laboratory.  MIT offers two sets of labeled, movie text data in BIO (Begining, Intermediate, Outside) format.  The BIO format a standard data format used with NER tools. The first data set is called "eng", is 1mb, and consists of simple questions related to movies.  The second dataset is called trivia, is 1.7mb and consists of more complex movie questions.  The data can be found here:

https://groups.csail.mit.edu/sls/downloads/movie/</p>

<br>

**Outcome**
<p>At the project's conclusion, I will better understand NER models and their abilities.  In particular, I should understand how to build a custom NER model based on a conditional random field.  I should be able to quantify the ability of both existing and custom NER models to correctly classify data from a custom data set.  I should be able to identify techniques that can be used to improve an NER's performance and offer both quantitative and qualitative assessments of their efficacy.</p>
